{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling with Pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   - **Supported by TingLin**\n",
    "   - **Kansas State University**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "  - **Extracting, transforming and selecting features**\n",
    "    \n",
    "- **Feature Extractors**\n",
    "     - [TF-IDF](#TF-IDF)\n",
    "     - [Word2Vec](#Word2Vec)\n",
    "     - [CountVectorizer](#CountVectorizer)\n",
    "- **Feature Transformers**\n",
    "     - [Tokenizer](#Tokenizer)\n",
    "     - [StopWordsRemover](#StopWordsRemover)\n",
    "     - [nn-gram](#nn-gram)\n",
    "     - [Binarizer](#Binarizer)\n",
    "     - [PCA](#PCA)\n",
    "     - [PolynomialExpansion](#PolynomialExpansion)\n",
    "     - [Discrete Cosine Transform (DCT)](#Discrete Cosine Transform)\n",
    "     - [StringIndexer](#StringIndexer)\n",
    "     - [IndexToString](#IndexToString)\n",
    "     - [OneHotEncoder](#OneHotEncoder)\n",
    "     - [VectorIndexer](#VectorIndexer)\n",
    "     - [Interaction](#Interaction)\n",
    "     - [Normalizer](#Normalizer)\n",
    "     - [StandardScaler](#StandardScaler)\n",
    "     - [MinMaxScaler](#MinMaxScaler)\n",
    "     - [MaxAbsScaler](#MaxAbsScaler)\n",
    "     - [Bucketizer](#Bucketizer)\n",
    "     - [ElementwiseProduct](#ElementwiseProduct)\n",
    "     - [SQLTransformer](#SQLTransformer)\n",
    "     - [VectorAssembler](#VectorAssembler)\n",
    "     - [QuantileDiscretizer](#QuantileDiscretizer)\n",
    "- **Feature Selectors**\n",
    "     - [VectorSlicer](#VectorSlicer)\n",
    "     - [RFormula](#RFormula)\n",
    "     - [ChiSqSelector](#ChiSqSelector)\n",
    "- **Clustering**\n",
    "     - [LDA](#LDA)\n",
    "- **LDA Topic Modeling with csv file**\n",
    "     - [LDA Topic Modeling with csv file](#LDA Topic Modeling with csv file)\n",
    "- ** Visualization**\n",
    "     - [Visualization](#Visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, CountVectorizer\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.linalg import Vectors, SparseVector\n",
    "from pyspark.ml.clustering import LDA, BisectingKMeans\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext, Row\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "from pyspark.mllib.clustering import LDA, LDAModel\n",
    "from pyspark.mllib.linalg import Vector, Vectors\n",
    "from pyspark.ml.feature import StopWordsRemover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext.getOrCreate()\n",
    "sqlContext = SQLContext(sc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------+---------+--------+------+--------+-----+-----------+--------------------+---+----------+\n",
      "|   id|        airline|     date|location|rating|   cabin|value|recommended|              review|uid|year_month|\n",
      "+-----+---------------+---------+--------+------+--------+-----+-----------+--------------------+---+----------+\n",
      "|10001|Delta Air Lines|21-Jun-14|Thailand|     7| Economy|    4|        YES|Flew Mar 30 NRT t...|  0|   21-Jun-|\n",
      "|10002|Delta Air Lines|19-Jun-14|     USA|     0| Economy|    2|         NO|Flight 2463 leavi...|  1|   19-Jun-|\n",
      "|10003|Delta Air Lines|18-Jun-14|     USA|     0| Economy|    1|         NO|Delta Website fro...|  2|   18-Jun-|\n",
      "|10004|Delta Air Lines|17-Jun-14|     USA|     9|Business|    4|        YES|\"I just returned ...|  3|   17-Jun-|\n",
      "|10005|Delta Air Lines|17-Jun-14| Ecuador|     7| Economy|    3|        YES|\"Round-trip fligh...|  4|   17-Jun-|\n",
      "|10006|Delta Air Lines|17-Jun-14|     USA|     9|Business|    5|        YES|Narita - Bangkok ...|  5|   17-Jun-|\n",
      "|10007|Delta Air Lines|14-Jun-14|      UK|     0| Economy|    1|         NO|Flight from NY La...|  6|   14-Jun-|\n",
      "|10008|Delta Air Lines|14-Jun-14|     USA|     0| Economy|    1|         NO|Originally I had ...|  7|   14-Jun-|\n",
      "|10009|Delta Air Lines|13-Jun-14|     USA|     4|Business|    2|         NO|We flew paid busi...|  8|   13-Jun-|\n",
      "|10010|Delta Air Lines|13-Jun-14|      UK|     9| Economy|    3|        YES|\"I flew from Heat...|  9|   13-Jun-|\n",
      "+-----+---------------+---------+--------+------+--------+-----+-----------+--------------------+---+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "rawdata = sqlContext.read.load(\"data/airlines2.csv\", format=\"csv\", header=True)\n",
    "rawdata = rawdata.fillna({'review': ''})                               # Replace nulls with blank string\n",
    "rawdata = rawdata.withColumn(\"uid\", monotonically_increasing_id())     # Create Unique ID\n",
    "rawdata = rawdata.withColumn(\"year_month\", rawdata.date.substr(1,7))   # Generate YYYY-MM variable\n",
    " \n",
    "# Show rawdata (as DataFrame)\n",
    "rawdata.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- unique id and words would be selected when doing topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleanup_text(record):\n",
    "    text  = record[8]\n",
    "    uid   = record[9]\n",
    "    words = text.split()  \n",
    "    # Default list of Stopwords\n",
    "    stopwords_core = ['a', u'about', u'above', u'after', u'again', u'against', u'all', u'am', u'an', u'and', u'any', u'are', u'arent', u'as', u'at', \n",
    "    u'be', u'because', u'been', u'before', u'being', u'below', u'between', u'both', u'but', u'by', \n",
    "    u'can', 'cant', 'come', u'could', 'couldnt', \n",
    "    u'd', u'did', u'didn', u'do', u'does', u'doesnt', u'doing', u'dont', u'down', u'during', \n",
    "    u'each', \n",
    "    u'few', 'finally', u'for', u'from', u'further', \n",
    "    u'had', u'hadnt', u'has', u'hasnt', u'have', u'havent', u'having', u'he', u'her', u'here', u'hers', u'herself', u'him', u'himself', u'his', u'how', \n",
    "    u'i', u'if', u'in', u'into', u'is', u'isnt', u'it', u'its', u'itself', \n",
    "    u'just', \n",
    "    u'll', \n",
    "    u'm', u'me', u'might', u'more', u'most', u'must', u'my', u'myself', \n",
    "    u'no', u'nor', u'not', u'now', \n",
    "    u'o', u'of', u'off', u'on', u'once', u'only', u'or', u'other', u'our', u'ours', u'ourselves', u'out', u'over', u'own', \n",
    "    u'r', u're', \n",
    "    u's', 'said', u'same', u'she', u'should', u'shouldnt', u'so', u'some', u'such', \n",
    "    u't', u'than', u'that', 'thats', u'the', u'their', u'theirs', u'them', u'themselves', u'then', u'there', u'these', u'they', u'this', u'those', u'through', u'to', u'too', \n",
    "    u'under', u'until', u'up', \n",
    "    u'very', \n",
    "    u'was', u'wasnt', u'we', u'were', u'werent', u'what', u'when', u'where', u'which', u'while', u'who', u'whom', u'why', u'will', u'with', u'wont', u'would', \n",
    "    u'y', u'you', u'your', u'yours', u'yourself', u'yourselves']\n",
    "    \n",
    "    # Custom List of Stopwords - Add your own here\n",
    "    stopwords_custom = ['']\n",
    "    stopwords = stopwords_core + stopwords_custom\n",
    "    stopwords = [word.lower() for word in stopwords]    \n",
    "    \n",
    "    text_out = [re.sub('[^a-zA-Z0-9]','',word) for word in words]                                       # Remove special characters\n",
    "    text_out = [word.lower() for word in text_out if len(word)>2 and word.lower() not in stopwords]     # Remove stopwords and words under X length\n",
    "    return text_out\n",
    "\n",
    "udf_cleantext = udf(cleanup_text , ArrayType(StringType()))\n",
    "clean_text = rawdata.withColumn(\"words\", udf_cleantext(struct([rawdata[x] for x in rawdata.columns])))\n",
    "\n",
    "# tokenizer = Tokenizer(inputCol=\"description\", outputCol=\"words\")\n",
    "# wordsData = tokenizer.transform(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- split review into words and then clean the words, finally add words as a new column on rawdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=u'10001', airline=u'Delta Air Lines', date=u'21-Jun-14', location=u'Thailand', rating=u'7', cabin=u'Economy', value=u'4', recommended=u'YES', review=u'Flew Mar 30 NRT to BKK. All flights were great. Flight was on-time and the in-flight entertainment was great. Apart from the meals - some Thai passengers cannot eat beef so the flight crews tried to ask other passengers who could eat beef and changed the meals around. We feel disappointed with their food services.', uid=0, year_month=u'21-Jun-', words=[u'flew', u'mar', u'nrt', u'bkk', u'flights', u'great', u'flight', u'ontime', u'inflight', u'entertainment', u'great', u'apart', u'meals', u'thai', u'passengers', u'cannot', u'eat', u'beef', u'flight', u'crews', u'tried', u'ask', u'passengers', u'eat', u'beef', u'changed', u'meals', u'around', u'feel', u'disappointed', u'food', u'services'])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show first row of clean_text\n",
    "clean_text.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Term Frequency Vectorization  - Option 2 (CountVectorizer)    : \n",
    "vectorizer = CountVectorizer(inputCol=\"words\", outputCol=\"Features\", vocabSize = 1000)\n",
    "vectorizer = vectorizer.fit(clean_text)\n",
    "featurizedData = vectorizer.transform(clean_text)\n",
    "\n",
    "vocablist = vectorizer.vocabulary\n",
    "vocab_broadcast = sc.broadcast(vocablist)\n",
    "\n",
    "idf = IDF(inputCol=\"Features\", outputCol=\"features\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "rescaledData = idfModel.transform(featurizedData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=u'10001', airline=u'Delta Air Lines', date=u'21-Jun-14', location=u'Thailand', rating=u'7', cabin=u'Economy', value=u'4', recommended=u'YES', review=u'Flew Mar 30 NRT to BKK. All flights were great. Flight was on-time and the in-flight entertainment was great. Apart from the meals - some Thai passengers cannot eat beef so the flight crews tried to ask other passengers who could eat beef and changed the meals around. We feel disappointed with their food services.', uid=0, year_month=u'21-Jun-', words=[u'flew', u'mar', u'nrt', u'bkk', u'flights', u'great', u'flight', u'ontime', u'inflight', u'entertainment', u'great', u'apart', u'meals', u'thai', u'passengers', u'cannot', u'eat', u'beef', u'flight', u'crews', u'tried', u'ask', u'passengers', u'eat', u'beef', u'changed', u'meals', u'around', u'feel', u'disappointed', u'food', u'services'], features=SparseVector(1000, {0: 0.4099, 3: 1.0601, 11: 1.2624, 25: 1.3913, 32: 3.4155, 46: 1.8131, 56: 4.3116, 97: 2.3469, 113: 2.5063, 201: 2.8577, 213: 2.9304, 249: 6.1442, 332: 3.3172, 346: 3.3454, 369: 3.435, 395: 3.4667, 490: 3.7227, 509: 3.8097, 537: 3.6819, 621: 8.2563, 693: 4.1281, 846: 8.6716}))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rescaledData.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-New column as features is added to the rescaleddata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "countVectors = vectorizer.transform(rescaledData).select(\"uid\", \"features\")\n",
    "from pyspark.mllib.feature import IDF\n",
    "frequencyVectors = countVectors.rdd.map(lambda vector: vector[1])\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "frequencyDenseVectors = frequencyVectors.map(lambda vector: Vectors.dense(vector))\n",
    "idf = IDF().fit(frequencyDenseVectors)\n",
    "tfidf = idf.transform(frequencyDenseVectors)\n",
    "corpus = tfidf.map(lambda x: [1, x]).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(uid=0, features=SparseVector(1000, {0: 2.0, 3: 1.0, 11: 1.0, 25: 1.0, 32: 2.0, 46: 1.0, 56: 2.0, 97: 1.0, 113: 1.0, 201: 1.0, 213: 1.0, 249: 2.0, 332: 1.0, 346: 1.0, 369: 1.0, 395: 1.0, 490: 1.0, 509: 1.0, 537: 1.0, 621: 2.0, 693: 1.0, 846: 2.0}))]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countVectors.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SparseVector(1000, {0: 2.0, 3: 1.0, 11: 1.0, 25: 1.0, 32: 2.0, 46: 1.0, 56: 2.0, 97: 1.0, 113: 1.0, 201: 1.0, 213: 1.0, 249: 2.0, 332: 1.0, 346: 1.0, 369: 1.0, 395: 1.0, 490: 1.0, 509: 1.0, 537: 1.0, 621: 2.0, 693: 1.0, 846: 2.0})]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the probability for each vectors\n",
    "frequencyVectors.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1,\n",
       "  DenseVector([0.4099, 0.0, 0.0, 1.0601, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.2624, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.3913, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.4155, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.8131, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.3116, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.3469, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.5063, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.8577, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.9304, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.1442, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.3172, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.3454, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.435, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.4667, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.7227, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.8097, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.6819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.2563, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.1281, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.6716, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ldaModel = LDA.train(corpus, k = 15, maxIterations=100, optimizer=\"online\", docConcentration=2.0, topicConcentration=3.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Build Latent Dirichlet Allocation model for clustering\n",
    "- Note: LDA does not perform well with the EMLDAOptimizer which is used by default. In the case of EMLDAOptimizer we have significant bies to the most popular hashtags. I used the OnlineLDAOptimizer instead. The Optimizer implements the Online variational Bayes LDA algorithm, which processes a subset of the corpus on each iteration, and updates the term-topic distribution adaptively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topicIndices = ldaModel.describeTopics(maxTermsPerTopic=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- each topic has maximun 5 terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocablist = vectorizer.vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- create vocabulary list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topicsRDD = sc.parallelize(topicIndices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'airline', 0.005468610076192595, 0),\n",
       " (u'united', 0.005435669548028015, 0),\n",
       " (u'crew', 0.004658161632933033, 0),\n",
       " (u'new', 0.004140039574989159, 0),\n",
       " (u'customers', 0.004007755348723611, 0)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "termsRDD.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- each terms and its probability with its topic number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "termsRDD = topicsRDD.map(lambda topic: (zip(operator.itemgetter(*topic[0])(vocablist), topic[1])))\n",
    "indexedTermsRDD = termsRDD.zipWithIndex()\n",
    "termsRDD = indexedTermsRDD.flatMap(lambda term: [(t[0], t[1], term[1]) for t in term[0]])\n",
    "termDF = termsRDD.toDF(['term', 'probability', 'topicId'])\n",
    "rawJson = termDF.toJSON().collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "from IPython.display import Javascript\n",
    "\n",
    "s = \"\"\n",
    "for line in rawJson:\n",
    "    s += (str(line) +',')\n",
    "stringJson = s[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- prepare the data and transform it into JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "html_code = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<meta charset=\"utf-8\">\n",
    "<style>\n",
    "\n",
    "circle {\n",
    "  fill: rgb(31, 119, 180);\n",
    "  fill-opacity: 0.5;\n",
    "  stroke: rgb(31, 119, 180);\n",
    "  stroke-width: 1px;\n",
    "}\n",
    "\n",
    ".leaf circle {\n",
    "  fill: #ff7f0e;\n",
    "  fill-opacity: 1;\n",
    "}\n",
    "\n",
    "text {\n",
    "  font: 14px sans-serif;\n",
    "}\n",
    "\n",
    "</style>\n",
    "<body>\n",
    "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\"></script>\n",
    "\n",
    "<script>\n",
    "\n",
    "var json = {\n",
    " \"name\": \"data\",\n",
    " \"children\": [\n",
    "  {\n",
    "     \"name\": \"topics\",\n",
    "     \"children\": [\n",
    "      %s\n",
    "     ]\n",
    "    }\n",
    "   ]\n",
    "};\n",
    "\n",
    "var r = 1500,\n",
    "    format = d3.format(\",d\"),\n",
    "    fill = d3.scale.category20c();\n",
    "\n",
    "var bubble = d3.layout.pack()\n",
    "    .sort(null)\n",
    "    .size([r, r])\n",
    "    .padding(1.5);\n",
    "\n",
    "var vis = d3.select(\"body\").append(\"svg\")\n",
    "    .attr(\"width\", r)\n",
    "    .attr(\"height\", r)\n",
    "    .attr(\"class\", \"bubble\");\n",
    "\n",
    "  \n",
    "var node = vis.selectAll(\"g.node\")\n",
    "    .data(bubble.nodes(classes(json))\n",
    "    .filter(function(d) { return !d.children; }))\n",
    "    .enter().append(\"g\")\n",
    "    .attr(\"class\", \"node\")\n",
    "    .attr(\"transform\", function(d) { return \"translate(\" + d.x + \",\" + d.y + \")\"; })\n",
    "    color = d3.scale.category20();\n",
    "  \n",
    "  node.append(\"title\")\n",
    "      .text(function(d) { return d.className + \": \" + format(d.value); });\n",
    "\n",
    "  node.append(\"circle\")\n",
    "      .attr(\"r\", function(d) { return d.r; })\n",
    "      .style(\"fill\", function(d) {return color(d.topicName);});\n",
    "\n",
    "var text = node.append(\"text\")\n",
    "    .attr(\"text-anchor\", \"middle\")\n",
    "    .attr(\"dy\", \".3em\")\n",
    "    .text(function(d) { return d.className.substring(0, d.r / 3)});\n",
    "  \n",
    "  text.append(\"tspan\")\n",
    "      .attr(\"dy\", \"1.2em\")\n",
    "      .attr(\"x\", 0)\n",
    "      .text(function(d) {return Math.ceil(d.value * 10000) /10000; });\n",
    "\n",
    "// Returns a flattened hierarchy containing all leaf nodes under the root.\n",
    "function classes(root) {\n",
    "  var classes = [];\n",
    "\n",
    "  function recurse(term, node) {\n",
    "    if (node.children) node.children.forEach(function(child) { recurse(node.term, child); });\n",
    "    else classes.push({topicName: node.topicId, className: node.term, value: node.probability});\n",
    "  }\n",
    "\n",
    "  recurse(null, root);\n",
    "  return {children: classes};\n",
    "}\n",
    "\n",
    "</script>\"\"\" % stringJson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- prepare the data and transform it into JSON format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"term\":\"airline\",\"probability\":0.005468610076192595,\"topicId\":0},{\"term\":\"united\",\"probability\":0.005435669548028015,\"topicId\":0},{\"term\":\"crew\",\"probability\":0.004658161632933033,\"topicId\":0},{\"term\":\"new\",\"probability\":0.004140039574989159,\"topicId\":0},{\"term\":\"customers\",\"probability\":0.004007755348723611,\"topicId\":0},{\"term\":\"delta\",\"probability\":0.004469610493552716,\"topicId\":1},{\"term\":\"flights\",\"probability\":0.0034390728858707284,\"topicId\":1},{\"term\":\"flew\",\"probability\":0.0032337163048356803,\"topicId\":1},{\"term\":\"new\",\"probability\":0.003176042499140196,\"topicId\":1},{\"term\":\"service\",\"probability\":0.003159285919025652,\"topicId\":1},{\"term\":\"angeles\",\"probability\":0.008186259720836014,\"topicId\":2},{\"term\":\"los\",\"probability\":0.008176865906048868,\"topicId\":2},{\"term\":\"airways\",\"probability\":0.006991519759146178,\"topicId\":2},{\"term\":\"paris\",\"probability\":0.006437592188145064,\"topicId\":2},{\"term\":\"oakland\",\"probability\":0.005378510725053001,\"topicId\":2},{\"term\":\"business\",\"probability\":0.010742445200316236,\"topicId\":3},{\"term\":\"good\",\"probability\":0.010736033157980832,\"topicId\":3},{\"term\":\"class\",\"probability\":0.01066845455852919,\"topicId\":3},{\"term\":\"seats\",\"probability\":0.007697537291731299,\"topicId\":3},{\"term\":\"delta\",\"probability\":0.0075765309286743845,\"topicId\":3},{\"term\":\"march\",\"probability\":0.009001823397094589,\"topicId\":4},{\"term\":\"sat\",\"probability\":0.00804446532215655,\"topicId\":4},{\"term\":\"dallas\",\"probability\":0.008015156117733973,\"topicId\":4},{\"term\":\"charlotte\",\"probability\":0.007861581418619312,\"topicId\":4},{\"term\":\"plane\",\"probability\":0.007703054321579884,\"topicId\":4},{\"term\":\"flights\",\"probability\":0.003964965918392413,\"topicId\":5},{\"term\":\"crew\",\"probability\":0.0034773903634442854,\"topicId\":5},{\"term\":\"united\",\"probability\":0.0034277017049599333,\"topicId\":5},{\"term\":\"delta\",\"probability\":0.003242119796406774,\"topicId\":5},{\"term\":\"flew\",\"probability\":0.003216870625527575,\"topicId\":5},{\"term\":\"extra\",\"probability\":0.012122309562960279,\"topicId\":6},{\"term\":\"seat\",\"probability\":0.011222719262309123,\"topicId\":6},{\"term\":\"pay\",\"probability\":0.009963639057966057,\"topicId\":6},{\"term\":\"economy\",\"probability\":0.009098925981156357,\"topicId\":6},{\"term\":\"plus\",\"probability\":0.008724794870461312,\"topicId\":6},{\"term\":\"southwest\",\"probability\":0.004960913496764307,\"topicId\":7},{\"term\":\"vegas\",\"probability\":0.004204330171825712,\"topicId\":7},{\"term\":\"las\",\"probability\":0.004015962322780218,\"topicId\":7},{\"term\":\"united\",\"probability\":0.0036145331275755075,\"topicId\":7},{\"term\":\"flights\",\"probability\":0.0033472910926461773,\"topicId\":7},{\"term\":\"boarding\",\"probability\":0.013408813314387376,\"topicId\":8},{\"term\":\"lga\",\"probability\":0.008452301532223745,\"topicId\":8},{\"term\":\"phl\",\"probability\":0.007906660188380312,\"topicId\":8},{\"term\":\"first\",\"probability\":0.0063868905595130185,\"topicId\":8},{\"term\":\"seat\",\"probability\":0.006028818447103835,\"topicId\":8},{\"term\":\"louisville\",\"probability\":0.00567258012318649,\"topicId\":9},{\"term\":\"houston\",\"probability\":0.005391395176628368,\"topicId\":9},{\"term\":\"flights\",\"probability\":0.004056095563189421,\"topicId\":9},{\"term\":\"denver\",\"probability\":0.003941632551395019,\"topicId\":9},{\"term\":\"united\",\"probability\":0.003925663709077897,\"topicId\":9},{\"term\":\"philadelphia\",\"probability\":0.014721455729197312,\"topicId\":10},{\"term\":\"dublin\",\"probability\":0.010810025717407225,\"topicId\":10},{\"term\":\"choice\",\"probability\":0.009766490473166292,\"topicId\":10},{\"term\":\"poor\",\"probability\":0.007346807702060231,\"topicId\":10},{\"term\":\"great\",\"probability\":0.006938994893603881,\"topicId\":10},{\"term\":\"united\",\"probability\":0.005418062513596403,\"topicId\":11},{\"term\":\"phx\",\"probability\":0.005104948202327995,\"topicId\":11},{\"term\":\"flights\",\"probability\":0.003816362591030766,\"topicId\":11},{\"term\":\"hnl\",\"probability\":0.0038063012218616183,\"topicId\":11},{\"term\":\"first\",\"probability\":0.0037047398604631533,\"topicId\":11},{\"term\":\"bags\",\"probability\":0.008889445409415352,\"topicId\":12},{\"term\":\"passengers\",\"probability\":0.005017265649919264,\"topicId\":12},{\"term\":\"proceeded\",\"probability\":0.004409956391158206,\"topicId\":12},{\"term\":\"class\",\"probability\":0.004052631086889068,\"topicId\":12},{\"term\":\"baggage\",\"probability\":0.003883895744602054,\"topicId\":12},{\"term\":\"gate\",\"probability\":0.010607492408536137,\"topicId\":13},{\"term\":\"told\",\"probability\":0.009833276968631807,\"topicId\":13},{\"term\":\"next\",\"probability\":0.009124715646822787,\"topicId\":13},{\"term\":\"line\",\"probability\":0.008681577927860406,\"topicId\":13},{\"term\":\"hours\",\"probability\":0.00864499029620592,\"topicId\":13},{\"term\":\"flights\",\"probability\":0.0037574295550019342,\"topicId\":14},{\"term\":\"staff\",\"probability\":0.0037118028173235853,\"topicId\":14},{\"term\":\"crew\",\"probability\":0.003634779935257936,\"topicId\":14},{\"term\":\"phoenix\",\"probability\":0.0035879186174758,\"topicId\":14},{\"term\":\"southwest\",\"probability\":0.003252064759164239,\"topicId\":14}'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stringJson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<!DOCTYPE html>\n",
       "<meta charset=\"utf-8\">\n",
       "<style>\n",
       "\n",
       "circle {\n",
       "  fill: rgb(31, 119, 180);\n",
       "  fill-opacity: 0.5;\n",
       "  stroke: rgb(31, 119, 180);\n",
       "  stroke-width: 1px;\n",
       "}\n",
       "\n",
       ".leaf circle {\n",
       "  fill: #ff7f0e;\n",
       "  fill-opacity: 1;\n",
       "}\n",
       "\n",
       "text {\n",
       "  font: 14px sans-serif;\n",
       "}\n",
       "\n",
       "</style>\n",
       "<body>\n",
       "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\"></script>\n",
       "\n",
       "<script>\n",
       "\n",
       "var json = {\n",
       " \"name\": \"data\",\n",
       " \"children\": [\n",
       "  {\n",
       "     \"name\": \"topics\",\n",
       "     \"children\": [\n",
       "      {\"term\":\"airline\",\"probability\":0.005468610076192595,\"topicId\":0},{\"term\":\"united\",\"probability\":0.005435669548028015,\"topicId\":0},{\"term\":\"crew\",\"probability\":0.004658161632933033,\"topicId\":0},{\"term\":\"new\",\"probability\":0.004140039574989159,\"topicId\":0},{\"term\":\"customers\",\"probability\":0.004007755348723611,\"topicId\":0},{\"term\":\"delta\",\"probability\":0.004469610493552716,\"topicId\":1},{\"term\":\"flights\",\"probability\":0.0034390728858707284,\"topicId\":1},{\"term\":\"flew\",\"probability\":0.0032337163048356803,\"topicId\":1},{\"term\":\"new\",\"probability\":0.003176042499140196,\"topicId\":1},{\"term\":\"service\",\"probability\":0.003159285919025652,\"topicId\":1},{\"term\":\"angeles\",\"probability\":0.008186259720836014,\"topicId\":2},{\"term\":\"los\",\"probability\":0.008176865906048868,\"topicId\":2},{\"term\":\"airways\",\"probability\":0.006991519759146178,\"topicId\":2},{\"term\":\"paris\",\"probability\":0.006437592188145064,\"topicId\":2},{\"term\":\"oakland\",\"probability\":0.005378510725053001,\"topicId\":2},{\"term\":\"business\",\"probability\":0.010742445200316236,\"topicId\":3},{\"term\":\"good\",\"probability\":0.010736033157980832,\"topicId\":3},{\"term\":\"class\",\"probability\":0.01066845455852919,\"topicId\":3},{\"term\":\"seats\",\"probability\":0.007697537291731299,\"topicId\":3},{\"term\":\"delta\",\"probability\":0.0075765309286743845,\"topicId\":3},{\"term\":\"march\",\"probability\":0.009001823397094589,\"topicId\":4},{\"term\":\"sat\",\"probability\":0.00804446532215655,\"topicId\":4},{\"term\":\"dallas\",\"probability\":0.008015156117733973,\"topicId\":4},{\"term\":\"charlotte\",\"probability\":0.007861581418619312,\"topicId\":4},{\"term\":\"plane\",\"probability\":0.007703054321579884,\"topicId\":4},{\"term\":\"flights\",\"probability\":0.003964965918392413,\"topicId\":5},{\"term\":\"crew\",\"probability\":0.0034773903634442854,\"topicId\":5},{\"term\":\"united\",\"probability\":0.0034277017049599333,\"topicId\":5},{\"term\":\"delta\",\"probability\":0.003242119796406774,\"topicId\":5},{\"term\":\"flew\",\"probability\":0.003216870625527575,\"topicId\":5},{\"term\":\"extra\",\"probability\":0.012122309562960279,\"topicId\":6},{\"term\":\"seat\",\"probability\":0.011222719262309123,\"topicId\":6},{\"term\":\"pay\",\"probability\":0.009963639057966057,\"topicId\":6},{\"term\":\"economy\",\"probability\":0.009098925981156357,\"topicId\":6},{\"term\":\"plus\",\"probability\":0.008724794870461312,\"topicId\":6},{\"term\":\"southwest\",\"probability\":0.004960913496764307,\"topicId\":7},{\"term\":\"vegas\",\"probability\":0.004204330171825712,\"topicId\":7},{\"term\":\"las\",\"probability\":0.004015962322780218,\"topicId\":7},{\"term\":\"united\",\"probability\":0.0036145331275755075,\"topicId\":7},{\"term\":\"flights\",\"probability\":0.0033472910926461773,\"topicId\":7},{\"term\":\"boarding\",\"probability\":0.013408813314387376,\"topicId\":8},{\"term\":\"lga\",\"probability\":0.008452301532223745,\"topicId\":8},{\"term\":\"phl\",\"probability\":0.007906660188380312,\"topicId\":8},{\"term\":\"first\",\"probability\":0.0063868905595130185,\"topicId\":8},{\"term\":\"seat\",\"probability\":0.006028818447103835,\"topicId\":8},{\"term\":\"louisville\",\"probability\":0.00567258012318649,\"topicId\":9},{\"term\":\"houston\",\"probability\":0.005391395176628368,\"topicId\":9},{\"term\":\"flights\",\"probability\":0.004056095563189421,\"topicId\":9},{\"term\":\"denver\",\"probability\":0.003941632551395019,\"topicId\":9},{\"term\":\"united\",\"probability\":0.003925663709077897,\"topicId\":9},{\"term\":\"philadelphia\",\"probability\":0.014721455729197312,\"topicId\":10},{\"term\":\"dublin\",\"probability\":0.010810025717407225,\"topicId\":10},{\"term\":\"choice\",\"probability\":0.009766490473166292,\"topicId\":10},{\"term\":\"poor\",\"probability\":0.007346807702060231,\"topicId\":10},{\"term\":\"great\",\"probability\":0.006938994893603881,\"topicId\":10},{\"term\":\"united\",\"probability\":0.005418062513596403,\"topicId\":11},{\"term\":\"phx\",\"probability\":0.005104948202327995,\"topicId\":11},{\"term\":\"flights\",\"probability\":0.003816362591030766,\"topicId\":11},{\"term\":\"hnl\",\"probability\":0.0038063012218616183,\"topicId\":11},{\"term\":\"first\",\"probability\":0.0037047398604631533,\"topicId\":11},{\"term\":\"bags\",\"probability\":0.008889445409415352,\"topicId\":12},{\"term\":\"passengers\",\"probability\":0.005017265649919264,\"topicId\":12},{\"term\":\"proceeded\",\"probability\":0.004409956391158206,\"topicId\":12},{\"term\":\"class\",\"probability\":0.004052631086889068,\"topicId\":12},{\"term\":\"baggage\",\"probability\":0.003883895744602054,\"topicId\":12},{\"term\":\"gate\",\"probability\":0.010607492408536137,\"topicId\":13},{\"term\":\"told\",\"probability\":0.009833276968631807,\"topicId\":13},{\"term\":\"next\",\"probability\":0.009124715646822787,\"topicId\":13},{\"term\":\"line\",\"probability\":0.008681577927860406,\"topicId\":13},{\"term\":\"hours\",\"probability\":0.00864499029620592,\"topicId\":13},{\"term\":\"flights\",\"probability\":0.0037574295550019342,\"topicId\":14},{\"term\":\"staff\",\"probability\":0.0037118028173235853,\"topicId\":14},{\"term\":\"crew\",\"probability\":0.003634779935257936,\"topicId\":14},{\"term\":\"phoenix\",\"probability\":0.0035879186174758,\"topicId\":14},{\"term\":\"southwest\",\"probability\":0.003252064759164239,\"topicId\":14}\n",
       "     ]\n",
       "    }\n",
       "   ]\n",
       "};\n",
       "\n",
       "var r = 1500,\n",
       "    format = d3.format(\",d\"),\n",
       "    fill = d3.scale.category20c();\n",
       "\n",
       "var bubble = d3.layout.pack()\n",
       "    .sort(null)\n",
       "    .size([r, r])\n",
       "    .padding(1.5);\n",
       "\n",
       "var vis = d3.select(\"body\").append(\"svg\")\n",
       "    .attr(\"width\", r)\n",
       "    .attr(\"height\", r)\n",
       "    .attr(\"class\", \"bubble\");\n",
       "\n",
       "  \n",
       "var node = vis.selectAll(\"g.node\")\n",
       "    .data(bubble.nodes(classes(json))\n",
       "    .filter(function(d) { return !d.children; }))\n",
       "    .enter().append(\"g\")\n",
       "    .attr(\"class\", \"node\")\n",
       "    .attr(\"transform\", function(d) { return \"translate(\" + d.x + \",\" + d.y + \")\"; })\n",
       "    color = d3.scale.category20();\n",
       "  \n",
       "  node.append(\"title\")\n",
       "      .text(function(d) { return d.className + \": \" + format(d.value); });\n",
       "\n",
       "  node.append(\"circle\")\n",
       "      .attr(\"r\", function(d) { return d.r; })\n",
       "      .style(\"fill\", function(d) {return color(d.topicName);});\n",
       "\n",
       "var text = node.append(\"text\")\n",
       "    .attr(\"text-anchor\", \"middle\")\n",
       "    .attr(\"dy\", \".3em\")\n",
       "    .text(function(d) { return d.className.substring(0, d.r / 3)});\n",
       "  \n",
       "  text.append(\"tspan\")\n",
       "      .attr(\"dy\", \"1.2em\")\n",
       "      .attr(\"x\", 0)\n",
       "      .text(function(d) {return Math.ceil(d.value * 10000) /10000; });\n",
       "\n",
       "// Returns a flattened hierarchy containing all leaf nodes under the root.\n",
       "function classes(root) {\n",
       "  var classes = [];\n",
       "\n",
       "  function recurse(term, node) {\n",
       "    if (node.children) node.children.forEach(function(child) { recurse(node.term, child); });\n",
       "    else classes.push({topicName: node.topicId, className: node.term, value: node.probability});\n",
       "  }\n",
       "\n",
       "  recurse(null, root);\n",
       "  return {children: classes};\n",
       "}\n",
       "\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize data using D3JS framework\n",
    "# Display the html\n",
    "display(HTML(html_code))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- D3 (Data-Driven Documents or D3.js) is a JavaScript library for visualizing data using web standards. D3 helps you bring data to life using SVG, Canvas and HTML. D3 combines powerful visualization and interaction techniques with a data-driven approach to DOM manipulation, giving you the full capabilities of modern browsers and the freedom to design the right visual interface for your data.\n",
    "- download d3.js, and put it at the same location as this files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
